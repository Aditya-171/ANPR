{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6d95eb-835e-4e79-b9b1-dc7e86a753cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20b4f4f-2f50-4e30-b6a5-bdba6360eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c54699a-8595-43ce-83b2-c9dc0759e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'croped_images'\n",
    "\n",
    "output_text_folder = 'croped_images_pred_easy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98072f47-b69e-4517-a3a8-6418cdf360c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    }
   ],
   "source": [
    "# Initialize the OCR reader\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee32f17-798a-4f59-a8b3-d752caf070f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c56c8-1f83-4ba6-9348-f6d8e34ff182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d01950a9-9a11-4eeb-9f4b-03e6949f520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame saved to anpr_numberplates_final_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"anpr_numberplates_final.xlsx\", header=None, names=['Car', 'Code'])\n",
    "\n",
    "df_cleaned = df.dropna(subset=['Code'])\n",
    "\n",
    "# Save the cleaned DataFrame to a new Excel file\n",
    "output_excel_path = \"anpr_numberplates_final_clean.xlsx\"\n",
    "df_cleaned.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Cleaned DataFrame saved to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512acf06-de01-40a8-bd03-f1e8ed571cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1d0a9-486a-4def-9bbe-4bf3e19fa1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b51d5-43f8-4b66-994b-4989d292f3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95363370-e659-4f62-a55c-71a86447feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted from 1.jpeg and saved to croped_images_pred\\1.txt\n",
      "Text extracted from 2.jpeg and saved to croped_images_pred\\2.txt\n",
      "Text extracted from 3.jpeg and saved to croped_images_pred\\3.txt\n",
      "Text extracted from 4.jpeg and saved to croped_images_pred\\4.txt\n",
      "Text extracted from 5.jpeg and saved to croped_images_pred\\5.txt\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each image in the folder\n",
    "for image_file in os.listdir(image_folder):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # Perform OCR on the image\n",
    "        result = reader.readtext(img)\n",
    "\n",
    "        # Extract the text from the result\n",
    "        extracted_text = ''.join([text_info[1] for text_info in result]).replace(' ', '').lower()\n",
    "\n",
    "        # Create a text file with the same name as the image and save the text\n",
    "        text_file_path = os.path.join(output_text_folder, os.path.splitext(image_file)[0] + '.txt')\n",
    "        with open(text_file_path, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(extracted_text)\n",
    "\n",
    "        print(f\"Text extracted from {image_file} and saved to {text_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c8f6d6-e1fc-4c3c-8d0d-b6c04eba5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Easy OCR: 0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder1 = 'croped_images_pred_easy'\n",
    "folder2 = 'croped_images_true'\n",
    "\n",
    "# Get the list of text files in each folder\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith('.txt')]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith('.txt')]\n",
    "\n",
    "# Check if the number of files in both folders is the same\n",
    "if len(files1) != len(files2):\n",
    "    print(\"Error: The number of files in the two folders is not the same.\")\n",
    "    exit()\n",
    "\n",
    "# Function to read the content of a text file\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Compare the content of each pair of text files\n",
    "matching_count = 0\n",
    "total_files = len(files1)\n",
    "\n",
    "for file_name in files1:\n",
    "    file_path1 = os.path.join(folder1, file_name)\n",
    "    file_path2 = os.path.join(folder2, file_name)\n",
    "\n",
    "    content1 = read_text_file(file_path1)\n",
    "    content2 = read_text_file(file_path2)\n",
    "\n",
    "    # Compare the content of the two text files\n",
    "    if content1 == content2:\n",
    "        matching_count += 1\n",
    "\n",
    "# Calculate the percentage of matching files\n",
    "percentage_matching = (matching_count / total_files) * 100\n",
    "\n",
    "print(f\"Accuracy of Easy OCR: {percentage_matching:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2307a-50ec-41ed-a5aa-a11705ac2622",
   "metadata": {},
   "source": [
    "## Keras ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e96f53f3-0495-44f7-9c83-b7eba545c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dc5daf6-efb0-46e1-8623-19601c9d9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb2b4fa-ebe9-4d1c-8020-fffc1af04618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\Aditya Soni\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\Aditya Soni\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_image_folder' with the path to your image folder\n",
    "image_folder = 'croped_images'\n",
    "\n",
    "# Replace 'output_text_folder' with the path where you want to save the text files\n",
    "output_text_folder = 'croped_images_pred_keras'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_text_folder):\n",
    "    os.makedirs(output_text_folder)\n",
    "\n",
    "# Initialize the OCR reader\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9578654-3132-45e4-b466-850f085573db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "595ace20-8023-4b99-ac24-a4ecec57c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "Text extracted from 1.jpeg and saved to croped_images_pred_keras\\1.txt\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "Text extracted from 2.jpeg and saved to croped_images_pred_keras\\2.txt\n",
      "1/1 [==============================] - 1s 826ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "Text extracted from 3.jpeg and saved to croped_images_pred_keras\\3.txt\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "Text extracted from 4.jpeg and saved to croped_images_pred_keras\\4.txt\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "Text extracted from 5.jpeg and saved to croped_images_pred_keras\\5.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras_ocr\n",
    "\n",
    "\n",
    "# Iterate through each image in the folder\n",
    "for image_file in os.listdir(image_folder):\n",
    "    if image_file.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        # Perform OCR on the image\n",
    "        predictions = pipeline.recognize([img])\n",
    "\n",
    "        # Extract the text from the predictions\n",
    "        extracted_text = ' '.join([word_info[0] for word_info in predictions[0]])\n",
    "\n",
    "        # Create a text file with the same name as the image and save the text\n",
    "        text_file_path = os.path.join(output_text_folder, os.path.splitext(image_file)[0] + '.txt')\n",
    "        with open(text_file_path, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(extracted_text)\n",
    "\n",
    "        print(f\"Text extracted from {image_file} and saved to {text_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef31eec2-1217-4782-bb37-bbb6d8c29aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of keras ocr: 0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder1 = 'croped_images_pred_keras'\n",
    "folder2 = 'croped_images_true'\n",
    "\n",
    "# Get the list of text files in each folder\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith('.txt')]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith('.txt')]\n",
    "\n",
    "# Check if the number of files in both folders is the same\n",
    "if len(files1) != len(files2):\n",
    "    print(\"Error: The number of files in the two folders is not the same.\")\n",
    "    exit()\n",
    "\n",
    "# Function to read the content of a text file\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Compare the content of each pair of text files\n",
    "matching_count = 0\n",
    "total_files = len(files1)\n",
    "\n",
    "for file_name in files1:\n",
    "    file_path1 = os.path.join(folder1, file_name)\n",
    "    file_path2 = os.path.join(folder2, file_name)\n",
    "\n",
    "    content1 = read_text_file(file_path1)\n",
    "    content2 = read_text_file(file_path2)\n",
    "\n",
    "    # Compare the content of the two text files\n",
    "    if content1 == content2:\n",
    "        matching_count += 1\n",
    "\n",
    "# Calculate the percentage of matching files\n",
    "percentage_matching = (matching_count / total_files) * 100\n",
    "\n",
    "print(f\"Accuracy of keras ocr: {percentage_matching:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242579ae-5f44-4eff-b3f1-b9ef9a0029a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7097dff9-5b26-4a1a-916d-be32518e6474",
   "metadata": {},
   "source": [
    "## new excel logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f809ce3e-887c-4886-bbeb-50f1224166e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f61b720-3fc8-4a3b-8c2b-378843f0b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('anpr_numberplates_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "39dc8c1a-6bf4-4186-932a-d45582a8dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel sheet into a pandas DataFrame\n",
    "#excel_file_path = \"anpr_numberplates_final.xlsx\"\n",
    "excel_file_path = 'anpr_numberplates_final_clean.xlsx'\n",
    "df = pd.read_excel(excel_file_path, header=None, names=['Car_name', 'Car_actual_text'])\n",
    "\n",
    "# Create a new column for predicted text\n",
    "df['Predicted_Text'] = \"\"\n",
    "\n",
    "# Define the path to the folder containing images\n",
    "image_folder_path = \"cropped_img/Cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92ec5627-8aa4-42ba-a3a2-500afeb0bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    # Define the list of special characters to remove\n",
    "    special_chars = ['.', ',', '-', '_', '@', '[', ']', \"'\", '(', ')', '#', '*', ':','~']\n",
    "    # Use a regular expression to remove the specified special characters\n",
    "    return re.sub(f\"[{''.join(re.escape(char) for char in special_chars)}]\", '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b612e065-e404-4580-b440-3ab98d220951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped_img/Cropped\n",
      "klc1ca2555\n",
      "pgonn12\n",
      "dzi7yxr\n",
      "pui8\n",
      "802lin\n",
      "y57213\n",
      "6526jhd\n",
      "nho14v8866\n",
      "tn\n",
      "hor5i6k\n",
      "fmh12867237\n",
      "durz1g\n",
      "alr486\n",
      "iiid\n",
      "ysizij\n",
      "ms66yob\n",
      "afr2011\n",
      "lrq\n",
      "9214\n",
      "hr26bc5514\n",
      "byha36\n",
      "huziq8\n",
      "dzi7yxr\n",
      "9214\n",
      "jp76546\n",
      "lbe\n",
      "manisa\n",
      "and\n",
      "lzcn5617\n",
      "midlyph\n",
      "fast\n",
      "ohgbcky\n",
      "hh15bd8877\n",
      "huziq8\n",
      "xntzdbg\n",
      "byha36\n",
      "mh208020\n",
      "ihgrod\n",
      "mhil\n",
      "alr486\n",
      "7049\n",
      "pui8\n",
      "yesboss\n",
      "hh15bd8877\n",
      "chioose\n",
      "tk378\n",
      "9214\n",
      "kl\n",
      "bkhl324\n",
      "mh010b0001\n",
      "miad\n",
      "0s\n",
      "4\n",
      "kattup\n",
      "hm\n",
      "tax\n",
      "orinnze\n",
      "9214\n",
      "cgraphics\n",
      "1268\n",
      "wl9ilc\n",
      "huziq8\n",
      "0ea44\n",
      "tn02bl\n",
      "choianoool\n",
      "nzi0lt\n",
      "pen15\n",
      "klc1ca2555\n",
      "mk01b8550\n",
      "dnig26\n",
      "dlcx4850\n",
      "elauh\n",
      "dl49ak49\n",
      "mh208020\n",
      "ka09\n",
      "frib025\n",
      "private\n",
      "ptbssz\n",
      "costarica\n",
      "lzcn5617\n",
      "wplatecoh\n",
      "ms66yob\n",
      "lr33teei\n",
      "gt\n",
      "ihzuav1450\n",
      "incar\n",
      "15lk10898\n",
      "private\n",
      "durz1g\n",
      "c\n",
      "virginia\n",
      "1n\n",
      "12012\n",
      "good\n",
      "522922\n",
      "48z4590\n",
      "washington\n",
      "m2laf\n",
      "brit0001\n",
      "iezbo64a7\n",
      "26spe4\n",
      "alr486\n",
      "choianoool\n",
      "kl5442670\n",
      "03ab3380\n",
      "e4gle\n",
      "e85sm\n",
      "lr33teei\n",
      "nho14v8866\n",
      "fhho1ae8o17\n",
      "03ab3380\n",
      "lr33teei\n",
      "kwid\n",
      "czi7kod\n",
      "nbyond\n",
      "notacop\n",
      "hr26bu0280\n",
      "k8i7cr\n",
      "v8\n",
      "fhho1ae8o17\n",
      "f65022\n",
      "kl65h4383\n",
      "did\n",
      "6cu56dg\n",
      "lol\n",
      "afr2011\n",
      "ka03mg\n",
      "mp055565\n",
      "26spe4\n",
      "fbe\n",
      "ja6zuar\n",
      "19s4523\n",
      "lr33teei\n",
      "gbietce\n",
      "up46icleo\n",
      "imau555\n",
      "6j03jl0126\n",
      "du\n",
      "15lk10898\n",
      "3sam123\n",
      "preallf\n",
      "ka03mg\n",
      "2180127\n",
      "hr26br9044\n",
      "tsl0}ic\n",
      "tn\n",
      "1433\n",
      "ka42h0052\n",
      "pgonn12\n",
      "qeel\n",
      "dan54p\n",
      "gotzpoo\n",
      "mh20ej0364\n",
      "lbe\n",
      "okla\n",
      "ka0ac5057\n",
      "mh20ee7598\n",
      "104u5333\n",
      "mh02cb\n",
      "fa\n",
      "m\n",
      "6cu56dg\n",
      "47222\n",
      "kuv\n",
      "410012749\n",
      "yesboss\n",
      "rxgigdu\n",
      "brit0001\n",
      "manisa\n",
      "baimar\n",
      "czi7kod\n",
      "4\n",
      "mh010b0001\n",
      "6861136\n",
      "hr26br9044\n",
      "midlyph\n",
      "lzcn5617\n",
      "baimar\n",
      "532h\n",
      "740246570\n",
      "gbietce\n",
      "cciao001\n",
      "145\n",
      "imau555\n",
      "ambo\n",
      "sdn7484u\n",
      "huziq8\n",
      "6526jhd\n",
      "kl01cc50\n",
      "kl5442670\n",
      "hch3\n",
      "sgosi\n",
      "lawyer\n",
      "m906090k\n",
      "hr26bc5514\n",
      "eab000\n",
      "hlwi\n",
      "pui8\n",
      "nbeyond\n",
      "6piv728\n",
      "jerse\n",
      "hr26bc5514\n",
      "alr486\n",
      "fallyou\n",
      "ka09\n",
      "lolcim\n",
      "700v\n",
      "tn99f2378\n",
      "m2laf\n",
      "dlcx4850\n",
      "pgonn12\n",
      "imau555\n",
      "1gm\n",
      "lr24cei29\n",
      "dzi7yxr\n",
      "mh20ej0364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(image_folder_path)\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    " \n",
    "total_images = 0\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    car_number = str(row['Car_name'])\n",
    "    \n",
    "    # Perform OCR on the image\n",
    "    if car_number and f\"{car_number}.png\" in os.listdir(image_folder_path):\n",
    "        image_path = os.path.join(image_folder_path, f\"{car_number}.png\")\n",
    "        #print(image_path)\n",
    "        result = reader.readtext(image_path)\n",
    "    \n",
    "        # Extract the text from OCR result and update the DataFrame\n",
    "        if result:\n",
    "            total_images += 1\n",
    "\n",
    "            #print(result[0][1])\n",
    "\n",
    "            predicted_text = result[0][1]\n",
    "            predicted_text = predicted_text.replace(\" \", \"\").lower()\n",
    "            predicted_text = remove_special_characters(predicted_text).lower()\n",
    "            df.at[index, 'Predicted_Text'] = predicted_text\n",
    "            print(predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d32b70fd-a8b2-4d42-ac67-21003445eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "#df['Column2'] = pd.to_numeric(df['Column2'], errors='coerce')\n",
    "\n",
    "#df['Accuracy'] = (df['Car_actual_text'].str.replace(\" \", \"\").str.lower() == df['Predicted_Text']).astype(int)\n",
    "df['Accuracy'] = (df['Car_actual_text'] == df['Predicted_Text']).astype(int)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = df['Accuracy'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "815d9cb8-3f68-450f-8a29-afd6843e726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 51.02%\n",
      "Total images- 216\n"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new Excel file\n",
    "output_excel_path = \"ocr_file_easy_neW.xlsx\"\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "print(\"Total images-\",total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067eb6c6-e82e-42ef-892d-276bf45dee63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4571e-ea60-45fd-a3bc-ddb7d849a4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d321e-ef12-4ca6-8880-1fa8054db624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6831ed-10a1-4e63-a9f9-2a042e88eee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01ffe707-6af9-41f2-a688-9827a2633d42",
   "metadata": {},
   "source": [
    "## keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "836ef2e7-50ac-480b-b5ab-d9c054f3e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\Aditya Soni\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\Aditya Soni\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "94d01369-746b-4981-bc73-22b8dadff032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "kln1ca255\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "mn112pg\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "dzizyxr\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "puibbes\n",
      "1/1 [==============================] - 1s 956ms/step\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "80211nvirginiamay07\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "ysx218\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "g526jhd\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "mhonavee66\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "cstinszcz6s\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "wor516k\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "mhi2bg7237\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "bjrz19\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "alr486\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "inzibyon\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "ysx2\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "m666yob\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 1s 655ms/step\n",
      "afr2011oonoason\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "irq\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "9214\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 491ms/step\n",
      "hr26bcssla\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "byht135\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "108evi242\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "dzizyxr\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "9214\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "jpkesa8\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "yd63lb\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "manisa\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "awd0x55\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "dlycn5617\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "midliyph\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "fastvurginia\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "ongbcky\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "mh15b18871\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "108evi242\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "nizdbg\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "byht135\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 1s 579ms/step\n",
      "mih20bs2oc\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "imgrootonnes\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 1s 529ms/step\n",
      "mhil1239gnind\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "alr486\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "8lcebol\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "puibbes\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "bossyes\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "mh15b18871\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "chioose\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "ltm376\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "9214\n",
      "1/1 [==============================] - 1s 548ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "klbbss\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "bokil321\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 1s 550ms/step\n",
      "mh01dbo001\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "\n",
      "1/1 [==============================] - 1s 630ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "8ozhnos\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "1/1 [==============================] - 1s 622ms/step\n",
      "30mmntoyote\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "upwatt\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "ten\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "taxi\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "orinnie\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "9214\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 739ms/step\n",
      "calographicsapegbfss8\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1268\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "ligtlc\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "108evi242\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "5474\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 1s 539ms/step\n",
      "tn02blyg\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "choianooo1\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "fl\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "olzionn\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "peni5\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "kln1ca255\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 1s 632ms/step\n",
      "01bb550mhcs\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "tic66\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "dlecx4850\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "dlcbds0\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "dla9ak49\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 1s 618ms/step\n",
      "mih20bs2oc\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "karoa2b6zma\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "emcb025\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "atepriv\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "fskdl\n",
      "1/1 [==============================] - 1s 622ms/step\n",
      "1/1 [==============================] - 0s 480ms/step\n",
      "ricacosta695299centroamerica\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "dlycn5617\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "wotplatecoa\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "m666yob\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "sisg\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "teelr33\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "gt\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "155tizta\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "inacar\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "15lk10898\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "atepriv\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "t\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "bjrz19\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 1s 520ms/step\n",
      "uko9c17\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "virginiawmygos\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_22/upsample_like_9/ResizeBilinear' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Aditya Soni\\AppData\\Local\\Temp\\ipykernel_16532\\3906703572.py\", line 9, in <module>\n      prediction_groups = pipeline.recognize([image_path])\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\pipeline.py\", line 62, in recognize\n      box_groups = self.detector.detect(images=images, **detection_kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\detection.py\", line 779, in detect\n      self.model.predict(np.array(images), **kwargs),\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2554, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\detection.py\", line 297, in call\n      if keras.backend.image_data_format() == \"channels_first\":\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\detection.py\", line 302, in call\n      source, size=(target_shape[1], target_shape[2]), half_pixel_centers=True\nNode: 'model_22/upsample_like_9/ResizeBilinear'\ninput image must be of non-zero size\n\t [[{{node model_22/upsample_like_9/ResizeBilinear}}]] [Op:__inference_predict_function_101581]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Use Keras OCR to recognize text in the image\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m prediction_groups \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mrecognize([image_path])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_groups:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Take the first prediction group and concatenate the recognized text\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     predicted_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word_info[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m word_info \u001b[38;5;129;01min\u001b[39;00m prediction_groups[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\pipeline.py:62\u001b[0m, in \u001b[0;36mPipeline.recognize\u001b[1;34m(self, images, detection_kwargs, recognition_kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognition_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     recognition_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 62\u001b[0m box_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mdetect(images\u001b[38;5;241m=\u001b[39mimages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdetection_kwargs)\n\u001b[0;32m     63\u001b[0m prediction_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39mrecognize_from_boxes(\n\u001b[0;32m     64\u001b[0m     images\u001b[38;5;241m=\u001b[39mimages, box_groups\u001b[38;5;241m=\u001b[39mbox_groups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrecognition_kwargs\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m box_groups \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     67\u001b[0m     tools\u001b[38;5;241m.\u001b[39madjust_boxes(boxes\u001b[38;5;241m=\u001b[39mboxes, boxes_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m scale)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m boxes\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m boxes, scale \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(box_groups, scales)\n\u001b[0;32m     71\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\detection.py:779\u001b[0m, in \u001b[0;36mDetector.detect\u001b[1;34m(self, images, detection_threshold, text_threshold, link_threshold, size_threshold, **kwargs)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Recognize the text in a set of images.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;124;03m    size_threshold: The minimum area for a word.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    777\u001b[0m images \u001b[38;5;241m=\u001b[39m [compute_input(tools\u001b[38;5;241m.\u001b[39mread(image)) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[0;32m    778\u001b[0m boxes \u001b[38;5;241m=\u001b[39m getBoxes(\n\u001b[1;32m--> 779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray(images), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    780\u001b[0m     detection_threshold\u001b[38;5;241m=\u001b[39mdetection_threshold,\n\u001b[0;32m    781\u001b[0m     text_threshold\u001b[38;5;241m=\u001b[39mtext_threshold,\n\u001b[0;32m    782\u001b[0m     link_threshold\u001b[38;5;241m=\u001b[39mlink_threshold,\n\u001b[0;32m    783\u001b[0m     size_threshold\u001b[38;5;241m=\u001b[39msize_threshold,\n\u001b[0;32m    784\u001b[0m )\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m boxes\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\anpr\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_22/upsample_like_9/ResizeBilinear' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Aditya Soni\\AppData\\Local\\Temp\\ipykernel_16532\\3906703572.py\", line 9, in <module>\n      prediction_groups = pipeline.recognize([image_path])\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\pipeline.py\", line 62, in recognize\n      box_groups = self.detector.detect(images=images, **detection_kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\detection.py\", line 779, in detect\n      self.model.predict(np.array(images), **kwargs),\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2554, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\detection.py\", line 297, in call\n      if keras.backend.image_data_format() == \"channels_first\":\n    File \"C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\keras_ocr\\detection.py\", line 302, in call\n      source, size=(target_shape[1], target_shape[2]), half_pixel_centers=True\nNode: 'model_22/upsample_like_9/ResizeBilinear'\ninput image must be of non-zero size\n\t [[{{node model_22/upsample_like_9/ResizeBilinear}}]] [Op:__inference_predict_function_101581]"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    car_name = str(row['Car_name'])\n",
    "    \n",
    "    # Perform OCR on the image\n",
    "    if car_name and f\"{car_name}.png\" in os.listdir(image_folder_path):\n",
    "        image_path = os.path.join(image_folder_path, f\"{car_name}.png\")\n",
    "        \n",
    "        # Use Keras OCR to recognize text in the image\n",
    "        prediction_groups = pipeline.recognize([image_path])\n",
    "        if prediction_groups:\n",
    "            # Take the first prediction group and concatenate the recognized text\n",
    "            predicted_text = ' '.join([word_info[0] for word_info in prediction_groups[0]])\n",
    "            \n",
    "            # Remove spaces and special characters, and convert to lowercase\n",
    "            predicted_text = predicted_text.replace(\" \", \"\").lower()\n",
    "            predicted_text = remove_special_characters(predicted_text).lower()\n",
    "            \n",
    "            df.at[index, 'Predicted_Text'] = predicted_text\n",
    "            print(predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7ec4feab-599c-439e-9af3-18354c94f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "#df['Column2'] = pd.to_numeric(df['Column2'], errors='coerce')\n",
    "\n",
    "#df['Accuracy'] = (df['Car_actual_text'].str.replace(\" \", \"\").str.lower() == df['Predicted_Text']).astype(int)\n",
    "df['Accuracy'] = (df['Car_actual_text'] == df['Predicted_Text']).astype(int)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = df['Accuracy'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c199054c-0a7f-4b5b-a824-c879d8212772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 31.84%\n",
      "Total images- 216\n"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new Excel file\n",
    "output_excel_path = \"ocr_file_keras_new.xlsx\"\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "print(\"Total images-\",total_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd52a5-e944-4f2a-b063-303b6b1fa940",
   "metadata": {},
   "source": [
    "# TR OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed68e41f-e151-4408-9308-701234964da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[torch]Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "     ---------------------------------------- 0.0/129.4 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/129.4 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/129.4 kB ? eta -:--:--\n",
      "     ----------- ------------------------- 41.0/129.4 kB 279.3 kB/s eta 0:00:01\n",
      "     -------------------------- ---------- 92.2/129.4 kB 581.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ 129.4/129.4 kB 583.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers[torch])\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 42.0/42.0 kB 991.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers[torch])\n",
      "  Downloading tokenizers-0.15.1-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers[torch])\n",
      "  Downloading safetensors-0.4.2-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.11 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from transformers[torch]) (2.1.2)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
      "  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from requests->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from requests->transformers[torch]) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aditya soni\\anaconda3\\envs\\anpr\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "   ---------------------------------------- 0.0/270.9 kB ? eta -:--:--\n",
      "   --------------------------------------  266.2/270.9 kB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 270.9/270.9 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "   ---------------------------------------- 0.0/330.1 kB ? eta -:--:--\n",
      "   --------------------------------------  327.7/330.1 kB 21.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 330.1/330.1 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.5/269.5 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.2-cp311-none-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.6/269.6 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 15.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.7/8.4 MB 21.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.1/8.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.5/8.4 MB 10.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.6/8.4 MB 9.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.9/8.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.3/8.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.7/8.4 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.9/8.4 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.1/8.4 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.4/8.4 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.6/8.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.8/8.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.1/8.4 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.4/8.4 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.8/8.4 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.0/8.4 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.3/8.4 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.6/8.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.0/8.4 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.4/8.4 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.8/8.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.4/8.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.7/8.4 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.1/8.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.4 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 6.5 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, accelerate, transformers\n",
      "Successfully installed accelerate-0.26.1 huggingface-hub-0.20.3 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.1 transformers-4.37.2\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2241ba1-36da-4fd4-80b3-953bdb86b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1246953f-37db-43bd-b67e-05b40eb64700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef377c8bdb3f48e4bc8e6b8c7c38164a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Aditya Soni\\.cache\\huggingface\\hub\\models--microsoft--trocr-large-printed. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e7e8c6ee28493fa43e335029e4bc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac766537dda14434b59a322410c0c1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae89d5f03764f49a3e66346b7f622e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41b82314eed492a9bfd0ec36483321b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b35062efbb464e8151e5d71dea6469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05bd68fb3cf47b088c27f1cd9ab960e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f5318efce440a68dc632e253677cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-printed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a735e079-507a-46fe-8b43-5bff34611671",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathStr=\"C:/Users/Aditya Soni/Desktop/ANPR/ocr/croped_images/3.jpeg\"\n",
    "def show_image(pathStr):\n",
    "  img = Image.open(pathStr).convert(\"RGB\")\n",
    "  #display(img)\n",
    "  return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22eab5-0269-462f-9d7f-d13e8884fda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f12d040b-6c59-4429-b96e-bc20afc6c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_ocr_image(src_img):\n",
    "  pixel_values = processor(images=src_img, return_tensors=\"pt\").pixel_values\n",
    "  generated_ids = model.generate(pixel_values)\n",
    "  return processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b429317-f60f-4e3d-a57c-8ebe2de0b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_image = show_image('croped_images/4.jpeg')\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2663a454-166f-4b88-8bc6-c87321f2a536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CGOAMF2250'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p='croped_images/4.jpeg'\n",
    "tr_ocr_image(show_image(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f67ff-ee19-4237-81f3-669c93bef657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d4b76-f012-423e-9e6b-46cb5dd600f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec6ab894-1a90-4c26-9f03-13a2aa8be38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame saved to anpr_numberplates_final_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"C:/Users/Aditya Soni/Downloads/anpr_numberplates_final (1).xlsx\", header=None, names=['Car_name', 'Code'])\n",
    "\n",
    "df = df.dropna(subset=['Code'])\n",
    "\n",
    "# Save the cleaned DataFrame to a new Excel file\n",
    "output_excel_path = \"anpr_numberplates_final_clean.xlsx\"\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Cleaned DataFrame saved to {output_excel_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "147f17b7-c8d1-4dc6-8394-8d3509c78fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Replace 'your_image_folder' with the path to your image folder\n",
    "image_folder = 'cropped_img/Cropped'\n",
    "\n",
    "# Replace 'output_text_folder' with the path where you want to save the text files\n",
    "output_text_folder = 'croped_images_pred_trocr'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_text_folder):\n",
    "    os.makedirs(output_text_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d1b26cf-5b03-4e8f-a77b-b915d769286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl01ca2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Soni\\anaconda3\\envs\\anpr\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgmn112\n",
      "dzi7yxr\n",
      "puibbes\n",
      "80211n\n",
      "ysx213\n",
      "g526jhd\n",
      "mh01av8866\n",
      "27575\n",
      "wor516k\n",
      "fmh12bg7237\n",
      "bjr216\n",
      "alr486\n",
      "tn2try0166\n",
      "ysx213\n",
      "ms66yob\n",
      "afr2011\n",
      "1rq\n",
      "yambaj\n",
      "9214\n",
      "hr26bc5514\n",
      "byhm136\n",
      "inv1298\n",
      "dzi7yxr\n",
      "apt1am09\n",
      "9214\n",
      "jpk6546\n",
      "yd63lb\n",
      "manisa\n",
      "ox65and\n",
      "dl7cn5617\n",
      "1k0188\n",
      "midlyph\n",
      "fast\n",
      "ongbcky\n",
      "mh15bd8877\n",
      "inv1298\n",
      "yntzdbg\n",
      "byhm136\n",
      "mh208020\n",
      "imgroot\n",
      "changeinqtyofreceiptforanoffer\n",
      "cashier\n",
      "alr486\n",
      "3040610\n",
      "puibbes\n",
      "yesboss\n",
      "mh15bd8877\n",
      "chioose\n",
      "ltm378\n",
      "9214\n",
      "boss\n",
      "bkwl324\n",
      "mh01db0001\n",
      "mh46p1651\n",
      "os802hn\n",
      "rmn306\n",
      "wattup\n",
      "item\n",
      "taxi\n",
      "orinnie\n",
      "9214\n",
      "sr\n",
      "1268\n",
      "liptlc\n",
      "inv1298\n",
      "us15474\n",
      "rmgst\n",
      "ch01an0001\n",
      "ifi\n",
      "rnz1017\n",
      "pen15\n",
      "kl01ca2555\n",
      "mh01bb550\n",
      "7vig263\n",
      "dl8cx4850\n",
      "du3cbd5092\n",
      "dl49ak49\n",
      "mh208020\n",
      "2662\n",
      "mcb025\n",
      "private\n",
      "pt8557k\n",
      "695299\n",
      "dl7cn5617\n",
      "007platecom\n",
      "ms66yob\n",
      "amount\n",
      "alr33tee\n",
      "gst\n",
      "tn21au1153\n",
      "inacar\n",
      "15lk10898\n",
      "$895\n",
      "private\n",
      "983\n",
      "bjr216\n",
      "ysc09\n",
      "wmy9051\n",
      "lentsk\n",
      "deinazer\n",
      "ev09ftw\n",
      "good\n",
      "522922\n",
      "4szw590\n",
      "mpeachw\n",
      "jhilhad\n",
      "vi2laf\n",
      "brit0001\n",
      "mzb0648\n",
      "26spf4\n",
      "alr486\n",
      "ch01an0001\n",
      "kl54a2670\n",
      "ka03ab3380\n",
      "e4gle\n",
      "889vsm\n",
      "thankyouforreversefordetails\n",
      "claz\n",
      "ka921\n",
      "alr33tee\n",
      "mh01av8866\n",
      "incho1ae8017\n",
      "ka03ab3380\n",
      "alr33tee\n",
      "kwid\n",
      "czi7kod\n",
      "nbyond\n",
      "notacop\n",
      "hr26bu0380\n",
      "k817gr\n",
      "v8\n",
      "incho1ae8017\n",
      "f65022\n",
      "kl65h4383\n",
      "prip\n",
      "invoice\n",
      "cu5600\n",
      "opeclol\n",
      "afr2011\n",
      "2525\n",
      "ka03mg2784\n",
      "tip055585\n",
      "26spf4\n",
      "vhb431\n",
      "tax38au777\n",
      "ja62uar\n",
      "tn19s4523\n",
      "mcb025\n",
      "rm\n",
      "alr33tee\n",
      "gbibtce\n",
      "d13\n",
      "upistc1366\n",
      "im4u555\n",
      "gj03jl0126\n",
      "tad00008\n",
      "15lk10898\n",
      "1cdaf\n",
      "3sam123\n",
      "preanup\n",
      "ka03mg2784\n",
      "2180127\n",
      "hr26br9044\n",
      "ts009tc258\n",
      "27575\n",
      "mh12de1433\n",
      "ka42n0852\n",
      "pgmn112\n",
      "h982fkl\n",
      "dan54p\n",
      "got2poo\n",
      "mh20ej0364\n",
      "yd63lb\n",
      "okla\n",
      "kaorac5957\n",
      "mh20ee7598\n",
      "in405333\n",
      "ictab&n\n",
      "mh02cb4545\n",
      "famu2010\n",
      "m771276\n",
      "cu5600\n",
      "qf7222\n",
      "kuys\n",
      "item\n",
      "tel018299\n",
      "yesboss\n",
      "trx61gdu\n",
      "brit0001\n",
      "manisa\n",
      "batman\n",
      "czi7kod\n",
      "486548\n",
      "rmn306\n",
      "mh01db0001\n",
      "6861136\n",
      "hr26br9044\n",
      "midlyph\n",
      "dl7cn5617\n",
      "batman\n",
      "s32h\n",
      "smokes\n",
      "ka02a6579\n",
      "1k0188\n",
      "gbibtce\n",
      "01cc1a0001\n",
      "8544\n",
      "145\n",
      "im4u555\n",
      "lambo\n",
      "sdn7484u\n",
      "inv1298\n",
      "g526jhd\n",
      "kl01cc50\n",
      "kl54a2670\n",
      "hnychil3\n",
      "sgq51ju\n",
      "lawyer\n",
      "m906090k\n",
      "hr26bcss14\n",
      "bab0001\n",
      "agetoil\n",
      "total8349\n",
      "puibbes\n",
      "inbeyond\n",
      "6ptv728\n",
      "j98257\n",
      "marina\n",
      "hr26bc5514\n",
      "alr486\n",
      "fallyou\n",
      "2662\n",
      "loloil\n",
      "700v\n",
      "tn99f2378\n",
      "vi2laf\n",
      "dl8cx4850\n",
      "pgmn112\n",
      "im4u555\n",
      "16m\n",
      "hr26cb1900\n",
      "dzi7yxr\n",
      "mh20ej0364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    car_name = str(row['Car_name'])\n",
    "    \n",
    "    # Perform OCR on the image\n",
    "    if car_name and f\"{car_name}.png\" in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, f\"{car_name}.png\")\n",
    "\n",
    "\n",
    "        predicted_text=  tr_ocr_image(show_image(image_path))\n",
    "        \n",
    "        \n",
    "        predicted_text = predicted_text.replace(\" \", \"\").lower()\n",
    "        predicted_text = remove_special_characters(predicted_text).lower()\n",
    "        \n",
    "        df.at[index, 'Predicted_Text'] = predicted_text\n",
    "        print(predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62f9e73c-8d0e-499c-8f11-f97d403a41e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Predicted_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars0</td>\n",
       "      <td>klg1ca2555</td>\n",
       "      <td>kl01ca2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cars1</td>\n",
       "      <td>pgmn112</td>\n",
       "      <td>pgmn112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cars3</td>\n",
       "      <td>dz17yxr</td>\n",
       "      <td>dzi7yxr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars4</td>\n",
       "      <td>pui8bes</td>\n",
       "      <td>puibbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cars6</td>\n",
       "      <td>80211n</td>\n",
       "      <td>80211n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Cars328</td>\n",
       "      <td>im4u555</td>\n",
       "      <td>im4u555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Cars329</td>\n",
       "      <td>16m</td>\n",
       "      <td>16m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Cars331</td>\n",
       "      <td>hr26cb1900</td>\n",
       "      <td>hr26cb1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Cars332</td>\n",
       "      <td>dz17yxr</td>\n",
       "      <td>dzi7yxr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Cars333</td>\n",
       "      <td>mh20ej0364</td>\n",
       "      <td>mh20ej0364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Car_name        Code Predicted_Text\n",
       "0      Cars0  klg1ca2555     kl01ca2555\n",
       "1      Cars1     pgmn112        pgmn112\n",
       "3      Cars3     dz17yxr        dzi7yxr\n",
       "4      Cars4     pui8bes        puibbes\n",
       "6      Cars6      80211n         80211n\n",
       "..       ...         ...            ...\n",
       "328  Cars328     im4u555        im4u555\n",
       "329  Cars329         16m            16m\n",
       "331  Cars331  hr26cb1900     hr26cb1900\n",
       "332  Cars332     dz17yxr        dzi7yxr\n",
       "333  Cars333  mh20ej0364     mh20ej0364\n",
       "\n",
       "[244 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3aadc91b-5471-4fbc-b8e4-f3803bb54a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "#df['Column2'] = pd.to_numeric(df['Column2'], errors='coerce')\n",
    "\n",
    "#df['Accuracy'] = (df['Car_actual_text'].str.replace(\" \", \"\").str.lower() == df['Predicted_Text']).astype(int)\n",
    "df['Accuracy'] = (df['Code'] == df['Predicted_Text']).astype(int)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = df['Accuracy'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76b6d707-519c-4044-9d49-756f35df1b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 50.41%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(output_excel_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal images-\u001b[39m\u001b[38;5;124m\"\u001b[39m,total_images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new Excel file\n",
    "output_excel_path = \"ocr_file_trocr.xlsx\"\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "print(\"Total images-\",total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab987ebe-655d-4080-be9e-fa1739bf41d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ee64b-7209-4390-8c9b-7b18995d4405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
